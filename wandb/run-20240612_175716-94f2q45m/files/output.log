LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name        | Type             | Params
-------------------------------------------------
0 | autoencoder | UNetAutoencoder  | 31.0 M
1 | model       | VGG              | 134 M
2 | criterion   | CrossEntropyLoss | 0
-------------------------------------------------
119 M     Trainable params
45.8 M    Non-trainable params
165 M     Total params
661.708   Total estimated model params size (MB)
c:\Users\tian_\AppData\Local\anaconda3\envs\Pytorch_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.
c:\Users\tian_\AppData\Local\anaconda3\envs\Pytorch_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.

Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]




Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:04<00:00, 11.49it/s, v_num=q45m, train_loss_step=2.340, train_acc_step=0.500]




Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.32it/s, v_num=q45m, train_loss_step=1.290, train_acc_step=0.750, valid_loss_step=1.360, valid_acc_step=0.571, valid_loss_epoch=1.290, valid_acc_epoch=0.617, valid_loss=1.290, valid_acc=0.614, train_loss_epoch=2.680, train_acc_epoch=0.281]





Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.35it/s, v_num=q45m, train_loss_step=2.710, train_acc_step=0.500, valid_loss_step=0.892, valid_acc_step=0.750, valid_loss_epoch=0.873, valid_acc_epoch=0.783, valid_loss=0.875, valid_acc=0.781, train_loss_epoch=1.640, train_acc_epoch=0.520]





Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.37it/s, v_num=q45m, train_loss_step=0.919, train_acc_step=0.750, valid_loss_step=0.921, valid_acc_step=0.786, valid_loss_epoch=0.853, valid_acc_epoch=0.767, valid_loss=0.857, valid_acc=0.768, train_loss_epoch=1.430, train_acc_epoch=0.582]




Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:17<00:00,  3.22it/s, v_num=q45m, train_loss_step=1.380, train_acc_step=0.500, valid_loss_step=1.050, valid_acc_step=0.679, valid_loss_epoch=0.832, valid_acc_epoch=0.767, valid_loss=0.846, valid_acc=0.761, train_loss_epoch=1.300, train_acc_epoch=0.622]





Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:17<00:00,  3.18it/s, v_num=q45m, train_loss_step=1.900, train_acc_step=0.250, valid_loss_step=0.554, valid_acc_step=0.821, valid_loss_epoch=0.766, valid_acc_epoch=0.783, valid_loss=0.753, valid_acc=0.786, train_loss_epoch=1.240, train_acc_epoch=0.632]





Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:15<00:00,  3.45it/s, v_num=q45m, train_loss_step=2.250, train_acc_step=0.500, valid_loss_step=0.766, valid_acc_step=0.786, valid_loss_epoch=0.764, valid_acc_epoch=0.800, valid_loss=0.764, valid_acc=0.799, train_loss_epoch=1.100, train_acc_epoch=0.655]





Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:15<00:00,  3.45it/s, v_num=q45m, train_loss_step=1.180, train_acc_step=0.500, valid_loss_step=0.629, valid_acc_step=0.857, valid_loss_epoch=0.722, valid_acc_epoch=0.800, valid_loss=0.716, valid_acc=0.804, train_loss_epoch=1.160, train_acc_epoch=0.645]





Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.42it/s, v_num=q45m, train_loss_step=2.080, train_acc_step=0.250, valid_loss_step=0.567, valid_acc_step=0.857, valid_loss_epoch=0.688, valid_acc_epoch=0.800, valid_loss=0.681, valid_acc=0.804, train_loss_epoch=1.030, train_acc_epoch=0.684]




Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.42it/s, v_num=q45m, train_loss_step=0.575, train_acc_step=0.750, valid_loss_step=0.585, valid_acc_step=0.786, valid_loss_epoch=0.659, valid_acc_epoch=0.800, valid_loss=0.655, valid_acc=0.799, train_loss_epoch=1.000, train_acc_epoch=0.705]






Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.39it/s, v_num=q45m, train_loss_step=0.0219, train_acc_step=1.000, valid_loss_step=0.418, valid_acc_step=0.857, valid_loss_epoch=0.660, valid_acc_epoch=0.800, valid_loss=0.645, valid_acc=0.804, train_loss_epoch=1.030, train_acc_epoch=0.694]





Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.40it/s, v_num=q45m, train_loss_step=0.982, train_acc_step=0.750, valid_loss_step=0.594, valid_acc_step=0.857, valid_loss_epoch=0.609, valid_acc_epoch=0.833, valid_loss=0.608, valid_acc=0.835, train_loss_epoch=0.938, train_acc_epoch=0.707]





Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.40it/s, v_num=q45m, train_loss_step=0.229, train_acc_step=1.000, valid_loss_step=0.589, valid_acc_step=0.750, valid_loss_epoch=0.664, valid_acc_epoch=0.800, valid_loss=0.660, valid_acc=0.797, train_loss_epoch=0.917, train_acc_epoch=0.718]





Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.43it/s, v_num=q45m, train_loss_step=1.200, train_acc_step=0.750, valid_loss_step=0.523, valid_acc_step=0.821, valid_loss_epoch=0.599, valid_acc_epoch=0.833, valid_loss=0.595, valid_acc=0.833, train_loss_epoch=0.903, train_acc_epoch=0.720]




Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.38it/s, v_num=q45m, train_loss_step=2.860, train_acc_step=0.000, valid_loss_step=0.590, valid_acc_step=0.786, valid_loss_epoch=0.589, valid_acc_epoch=0.850, valid_loss=0.589, valid_acc=0.846, train_loss_epoch=0.871, train_acc_epoch=0.738]




Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.34it/s, v_num=q45m, train_loss_step=2.510, train_acc_step=0.500, valid_loss_step=0.716, valid_acc_step=0.857, valid_loss_epoch=0.643, valid_acc_epoch=0.850, valid_loss=0.648, valid_acc=0.850, train_loss_epoch=0.847, train_acc_epoch=0.747]






Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:15<00:00,  3.47it/s, v_num=q45m, train_loss_step=0.843, train_acc_step=0.500, valid_loss_step=0.321, valid_acc_step=0.929, valid_loss_epoch=0.600, valid_acc_epoch=0.833, valid_loss=0.582, valid_acc=0.839, train_loss_epoch=0.868, train_acc_epoch=0.737]





Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.40it/s, v_num=q45m, train_loss_step=0.821, train_acc_step=0.750, valid_loss_step=0.761, valid_acc_step=0.786, valid_loss_epoch=0.668, valid_acc_epoch=0.817, valid_loss=0.674, valid_acc=0.815, train_loss_epoch=0.794, train_acc_epoch=0.753]





Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.43it/s, v_num=q45m, train_loss_step=0.760, train_acc_step=0.750, valid_loss_step=0.625, valid_acc_step=0.786, valid_loss_epoch=0.621, valid_acc_epoch=0.833, valid_loss=0.621, valid_acc=0.830, train_loss_epoch=0.787, train_acc_epoch=0.764]


Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:21<00:00,  2.56it/s, v_num=q45m, train_loss_step=0.760, train_acc_step=0.750, valid_loss_step=0.861, valid_acc_step=0.821, valid_loss_epoch=0.662, valid_acc_epoch=0.867, valid_loss=0.674, valid_acc=0.864, train_loss_epoch=0.829, train_acc_epoch=0.750]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
c:\Users\tian_\AppData\Local\anaconda3\envs\Pytorch_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.
c:\Users\tian_\AppData\Local\anaconda3\envs\Pytorch_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:436: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.

Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 13.96it/s]
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
c:\Users\tian_\AppData\Local\anaconda3\envs\Pytorch_env\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
c:\Users\tian_\AppData\Local\anaconda3\envs\Pytorch_env\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
c:\Users\tian_\AppData\Local\anaconda3\envs\Pytorch_env\Lib\site-packages\pytorch_lightning\loggers\wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
c:\Users\tian_\AppData\Local\anaconda3\envs\Pytorch_env\Lib\site-packages\pytorch_lightning\callbacks\model_checkpoint.py:653: Checkpoint directory .\Proyecto3\94f2q45m\checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name        | Type             | Params
-------------------------------------------------
0 | autoencoder | UNetAutoencoder  | 31.0 M
1 | model       | VGG              | 134 M
2 | criterion   | CrossEntropyLoss | 0
-------------------------------------------------
119 M     Trainable params
45.8 M    Non-trainable params
165 M     Total params
661.708   Total estimated model params size (MB)




Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:04<00:00, 11.08it/s, v_num=q45m, train_loss_step=2.150, train_acc_step=0.250]





Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:15<00:00,  3.44it/s, v_num=q45m, train_loss_step=1.630, train_acc_step=0.250, valid_loss_step=1.520, valid_acc_step=0.679, valid_loss_epoch=1.330, valid_acc_epoch=0.717, valid_loss=1.340, valid_acc=0.714, train_loss_epoch=2.720, train_acc_epoch=0.262]





Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.40it/s, v_num=q45m, train_loss_step=0.722, train_acc_step=0.750, valid_loss_step=0.889, valid_acc_step=0.750, valid_loss_epoch=0.911, valid_acc_epoch=0.717, valid_loss=0.909, valid_acc=0.719, train_loss_epoch=1.670, train_acc_epoch=0.527]




Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.39it/s, v_num=q45m, train_loss_step=0.565, train_acc_step=0.750, valid_loss_step=1.060, valid_acc_step=0.750, valid_loss_epoch=0.834, valid_acc_epoch=0.800, valid_loss=0.848, valid_acc=0.797, train_loss_epoch=1.420, train_acc_epoch=0.576]





Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.36it/s, v_num=q45m, train_loss_step=0.321, train_acc_step=1.000, valid_loss_step=0.404, valid_acc_step=0.893, valid_loss_epoch=0.824, valid_acc_epoch=0.733, valid_loss=0.798, valid_acc=0.743, train_loss_epoch=1.240, train_acc_epoch=0.632]





Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.34it/s, v_num=q45m, train_loss_step=1.250, train_acc_step=0.750, valid_loss_step=0.914, valid_acc_step=0.750, valid_loss_epoch=0.761, valid_acc_epoch=0.800, valid_loss=0.771, valid_acc=0.797, train_loss_epoch=1.200, train_acc_epoch=0.641]





Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.34it/s, v_num=q45m, train_loss_step=0.424, train_acc_step=1.000, valid_loss_step=0.744, valid_acc_step=0.786, valid_loss_epoch=0.728, valid_acc_epoch=0.767, valid_loss=0.729, valid_acc=0.768, train_loss_epoch=1.120, train_acc_epoch=0.659]





Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.32it/s, v_num=q45m, train_loss_step=2.560, train_acc_step=0.500, valid_loss_step=0.620, valid_acc_step=0.786, valid_loss_epoch=0.688, valid_acc_epoch=0.833, valid_loss=0.684, valid_acc=0.830, train_loss_epoch=1.060, train_acc_epoch=0.677]





Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.42it/s, v_num=q45m, train_loss_step=1.490, train_acc_step=0.500, valid_loss_step=0.969, valid_acc_step=0.714, valid_loss_epoch=0.692, valid_acc_epoch=0.817, valid_loss=0.709, valid_acc=0.810, train_loss_epoch=1.030, train_acc_epoch=0.703]





Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.42it/s, v_num=q45m, train_loss_step=1.210, train_acc_step=0.500, valid_loss_step=0.811, valid_acc_step=0.786, valid_loss_epoch=0.636, valid_acc_epoch=0.833, valid_loss=0.646, valid_acc=0.830, train_loss_epoch=0.997, train_acc_epoch=0.691]





Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.39it/s, v_num=q45m, train_loss_step=1.730, train_acc_step=0.500, valid_loss_step=0.704, valid_acc_step=0.857, valid_loss_epoch=0.670, valid_acc_epoch=0.833, valid_loss=0.672, valid_acc=0.835, train_loss_epoch=0.957, train_acc_epoch=0.719]




Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.42it/s, v_num=q45m, train_loss_step=0.648, train_acc_step=0.750, valid_loss_step=0.579, valid_acc_step=0.857, valid_loss_epoch=0.660, valid_acc_epoch=0.850, valid_loss=0.655, valid_acc=0.850, train_loss_epoch=0.964, train_acc_epoch=0.700]





Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.38it/s, v_num=q45m, train_loss_step=0.544, train_acc_step=1.000, valid_loss_step=0.852, valid_acc_step=0.821, valid_loss_epoch=0.619, valid_acc_epoch=0.850, valid_loss=0.633, valid_acc=0.848, train_loss_epoch=0.925, train_acc_epoch=0.730]




Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.43it/s, v_num=q45m, train_loss_step=1.020, train_acc_step=0.500, valid_loss_step=0.707, valid_acc_step=0.821, valid_loss_epoch=0.636, valid_acc_epoch=0.817, valid_loss=0.641, valid_acc=0.817, train_loss_epoch=0.931, train_acc_epoch=0.707]






Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.42it/s, v_num=q45m, train_loss_step=1.730, train_acc_step=0.500, valid_loss_step=0.660, valid_acc_step=0.821, valid_loss_epoch=0.645, valid_acc_epoch=0.817, valid_loss=0.646, valid_acc=0.817, train_loss_epoch=0.838, train_acc_epoch=0.744]





Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.38it/s, v_num=q45m, train_loss_step=1.920, train_acc_step=0.500, valid_loss_step=0.559, valid_acc_step=0.821, valid_loss_epoch=0.610, valid_acc_epoch=0.817, valid_loss=0.607, valid_acc=0.817, train_loss_epoch=0.908, train_acc_epoch=0.733]





Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.37it/s, v_num=q45m, train_loss_step=1.440, train_acc_step=0.500, valid_loss_step=0.524, valid_acc_step=0.857, valid_loss_epoch=0.613, valid_acc_epoch=0.833, valid_loss=0.607, valid_acc=0.835, train_loss_epoch=0.834, train_acc_epoch=0.757]





Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:16<00:00,  3.40it/s, v_num=q45m, train_loss_step=0.095, train_acc_step=1.000, valid_loss_step=0.505, valid_acc_step=0.857, valid_loss_epoch=0.648, valid_acc_epoch=0.833, valid_loss=0.639, valid_acc=0.835, train_loss_epoch=0.828, train_acc_epoch=0.754]


Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:21<00:00,  2.54it/s, v_num=q45m, train_loss_step=0.095, train_acc_step=1.000, valid_loss_step=0.499, valid_acc_step=0.857, valid_loss_epoch=0.676, valid_acc_epoch=0.833, valid_loss=0.665, valid_acc=0.835, train_loss_epoch=0.834, train_acc_epoch=0.746]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 14.06it/s]
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name        | Type             | Params
-------------------------------------------------
0 | autoencoder | UNetAutoencoder  | 31.0 M
1 | model       | VGG              | 134 M
2 | criterion   | CrossEntropyLoss | 0
-------------------------------------------------
119 M     Trainable params
45.8 M    Non-trainable params
165 M     Total params
661.708   Total estimated model params size (MB)


Epoch 0:   4%|â–Ž         | 2/55 [00:00<00:08,  6.06it/s, v_num=q45m, train_loss_step=3.700, train_acc_step=0.0625]
c:\Users\tian_\AppData\Local\anaconda3\envs\Pytorch_env\Lib\site-packages\pytorch_lightning\trainer\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...



